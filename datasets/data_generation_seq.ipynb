{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from noise import *\n",
    "import random\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split  # Import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x values\n",
    "def generate_x_values(start_x, end_x, n_datapoints, n_samples):\n",
    "    # create n x values\n",
    "    xs = np.linspace(start_x, end_x, n_datapoints)\n",
    "    xs = np.tile(xs, (n_samples, 1))\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True functions\n",
    "def sin(xs):\n",
    "    return np.sin(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise functions\n",
    "def pink(xs, amplitude):\n",
    "    # Maybe change to y_true as input (instead of xs)\n",
    "    y_added_noise = np.zeros(xs.shape)\n",
    "    for sample in range(xs.shape[0]):\n",
    "        y_added_noise[sample, :] = amplitude*pink_noise(xs[sample, :])\n",
    "    return y_added_noise\n",
    "\n",
    "def uniform(xs, lower_bound, upper_bound):\n",
    "    return np.random.uniform(lower_bound, upper_bound)\n",
    "\n",
    "def gaussian(xs, std):\n",
    "    return np.random.normal(0, std, xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR\n",
    "def calculate_snr(y_true, y_noise): ### write own code later\n",
    "    # Calculate signal power\n",
    "    signal_power = np.mean(y_true ** 2)\n",
    "    # Calculate noise power\n",
    "    noise_power = np.mean((y_noise - y_true) ** 2)\n",
    "    # Calculate (linear) SNR\n",
    "    snr = signal_power / noise_power\n",
    "    # Convert to dB\n",
    "    snr_db = 10 * np.log10(snr)\n",
    "    return snr, snr_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "n_datapoints = 30  # number of (total) datapoints generated\n",
    "n_samples = 100\n",
    "start_x, end_x = -10, 10  # x values to be used\n",
    "\n",
    "# Train/validation/test split parameters\n",
    "train_size = 0.7\n",
    "validation_size = 0.1\n",
    "test_size = 0.2\n",
    "\n",
    "# Function parameters\n",
    "func = sin  # Available: x, x_sq, sin\n",
    "\n",
    "# Noise parameters\n",
    "noise = gaussian  #  #TODO Available: pink, uniform, gaussian\n",
    "\n",
    "amplitude = None  \n",
    "upper_bound, lower_bound = None, None\n",
    "std = None\n",
    "\n",
    "if noise == pink:\n",
    "    amplitude = 0.001 # We want values: amplitude in (0.01, 20), to get snr_db in approx. (-30, 40) for sin(x) \n",
    "elif noise == uniform:\n",
    "    upper_bound, lower_bound = -0.01, 0.01  # We want values: upper_bound, lower_bound in (-0.01, 0.01) to (-20, 20), to ge snr_db in approx. (-30, 40) for sin(x)\n",
    "elif noise == gaussian:\n",
    "    std = 4.5 #Mellan [0.01, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 30)\n"
     ]
    }
   ],
   "source": [
    "# Dataset generation\n",
    "xs = generate_x_values(start_x, end_x, n_datapoints, n_samples)  # x values\n",
    "#print(xs.shape)\n",
    "y_true = func(xs)\n",
    "\n",
    "if noise == pink:\n",
    "    y_added_noise = noise(xs, amplitude)\n",
    "elif noise == uniform:\n",
    "    y_added_noise = noise(xs, lower_bound, upper_bound)\n",
    "elif noise == gaussian:\n",
    "    y_added_noise = noise(xs, std)\n",
    "\n",
    "y_noise = y_true + y_added_noise\n",
    "print(y_noise.shape)\n",
    "\n",
    "# Calculate snr, snr_db for the entire dataset\n",
    "snr, snr_db = calculate_snr(y_true, y_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 0.022667274416647558 DB: -16.446006976491002\n"
     ]
    }
   ],
   "source": [
    "sum_snr = 0\n",
    "sum_snr_db = 0\n",
    "for i in range(y_noise.shape[0]):\n",
    "        \n",
    "    snr_, snr_db = calculate_snr(y_true, y_noise)\n",
    "    sum_snr += snr_\n",
    "    sum_snr_db += snr_db\n",
    "\n",
    "snr_ = sum_snr / y_noise.shape[0]\n",
    "snr_db_ = sum_snr_db / y_noise.shape[0]\n",
    "print(f\"SNR: {snr_} DB: {snr_db_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data\n",
    "# create the datasets in dataframe format\n",
    "true_data_df = pd.DataFrame(y_true)\n",
    "\n",
    "noisy_data_df = pd.DataFrame(y_noise)\n",
    "\n",
    "\n",
    "# Step 1: Split 80% for training/validation and 20% for testing\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    noisy_data_df,  \n",
    "    true_data_df,\n",
    "    test_size=0.2,   # 20% for testing\n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "# Step 2: Split the remaining 80% into 70% training and 10% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, \n",
    "    y_temp,\n",
    "    test_size=0.125,  # 10% of the original total = 0.1 / 0.8 = 0.125\n",
    "    random_state=42  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "if save:\n",
    "    func_name = func.__name__\n",
    "    noise_name = noise.__name__\n",
    "    name = func_name + \"_\" + noise_name + \"_\" + str(round(snr_db_, 2))\n",
    "    folder_name = f\"../datasets/seq_{name}\"\n",
    "\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    y_train.to_csv(f'{folder_name}/y_data_train.csv', index=False)\n",
    "    y_val.to_csv(f'{folder_name}/y_data_val.csv', index=False)\n",
    "    y_test.to_csv(f'{folder_name}/y_data_test.csv', index=False)\n",
    "    X_train.to_csv(f'{folder_name}/X_data_train.csv', index=False)\n",
    "    X_val.to_csv(f'{folder_name}/X_data_val.csv', index=False)\n",
    "    X_test.to_csv(f'{folder_name}/X_data_test.csv', index=False)\n",
    "\n",
    "    \n",
    "\n",
    "    with open(f'{folder_name}/meta_data.txt', \"w\") as file:\n",
    "        # Write text to the file\n",
    "        file.write(f\"n_samples: {n_samples}\\n\")\n",
    "        file.write(f\"n_datapoints: {n_datapoints}\\n\")\n",
    "        file.write(f\"start_x, end_x: {start_x, end_x }\\n\")\n",
    "        file.write(f\"function: {func_name}\\n\")\n",
    "        file.write(f\"noise: {noise_name}\\n\")\n",
    "        file.write(f\"snr, snr_db: {snr, snr_db}\\n\\n\")\n",
    "        file.write(f\"Noise specific\\n\")\n",
    "        file.write(f\"(pink noise only) amplitude: {amplitude}\\n\")\n",
    "        file.write(f\"(uniform noise only) upper_bound, lower_bound: {upper_bound, lower_bound}\\n\")\n",
    "        file.write(f\"(gaussian noise only) std: {std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
