{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import DeepMIMOv3 as DeepMIMO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from noise import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(scenario_name, \n",
    "                   n_bs_y, n_bs_x, n_ue_y, n_ue_x, \n",
    "                   n_paths, n_subcarriers):\n",
    "    # Load the default params, set constant params\n",
    "    params = DeepMIMO.default_params()\n",
    "    params['dataset_folder'] = r'scenarios'\n",
    "    \n",
    "    # Set params\n",
    "    # Which scenario\n",
    "    params['scenario'] = scenario_name\n",
    "    # For the antennas\n",
    "    params['bs_antenna']['shape'] = np.array([n_bs_y, n_bs_x])\n",
    "    params['ue_antenna']['shape'] = np.array([n_ue_y, n_ue_x])\n",
    "    # For the path\n",
    "    params['num_paths'] = n_paths\n",
    "    params['OFDM']['subcarriers'] = n_subcarriers\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = DeepMIMO.generate_data(params)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_H(dataset, user):\n",
    "    i = 0  # Only one base station in scenario I2\n",
    "    j = user  # Choose the first user\n",
    "    H = dataset[i]['user']['channel'][j]\n",
    "    H = H[:, :, 0]  # Choose the first subcarrier\n",
    "    return H\n",
    "\n",
    "def generate_H_abs(dataset, user):\n",
    "    H = generate_H(dataset, user)\n",
    "    H_abs = np.abs(H)\n",
    "\n",
    "    return H_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise functions\n",
    "def gaussian(H_true, std):\n",
    "    return np.random.normal(0, std, H_true.shape)\n",
    "\n",
    "def pink(H_true, amplitude):\n",
    "    return amplitude*pink_noise(H_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR\n",
    "def calculate_snr(y_true, y_noise): ### write own code later\n",
    "    # Calculate signal power\n",
    "    signal_power = np.mean(y_true ** 2)\n",
    "    # Calculate noise power\n",
    "    noise_power = np.mean((y_noise - y_true) ** 2)\n",
    "    # Calculate (linear) SNR\n",
    "    snr = signal_power / noise_power\n",
    "    # Convert to dB\n",
    "    snr_db = 10 * np.log10(snr)\n",
    "    return snr, snr_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_H(H_true, noise):\n",
    "    # noise = np.random.normal(0, 10**(-5), H.shape)\n",
    "    std = 10**(-4)\n",
    "    if noise == gaussian:\n",
    "        H_added_noise = gaussian(H_true, std)\n",
    "    elif noise == 'pink':\n",
    "        H_added_noise = np.zeros(H_true.shape)\n",
    "\n",
    "    H_noise = H_true + H_added_noise\n",
    "\n",
    "    return H_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmat(H):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(H.T, cmap='viridis', aspect='auto', origin='lower', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title('Channel Gain Magnitude of (RX, TX) Antenna Pairs')\n",
    "    plt.xlabel('RX antenna')\n",
    "    plt.ylabel('TX antenna')\n",
    "    # plt.xticks(ticks=np.arange(H.shape[0]), labels=np.arange(1, H.shape[0] + 1))\n",
    "    # plt.yticks(ticks=np.arange(H.shape[1]), labels=np.arange(1, H.shape[1] + 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(scenario_name, \n",
    "                    n_bs_y, n_bs_x, n_ue_y, n_ue_x,\n",
    "                    n_paths, n_subcarriers,user):\n",
    "    dataset = create_dataset(scenario_name, n_bs_y, n_bs_x, n_ue_y, n_ue_x, n_paths, n_subcarriers)\n",
    "    #H_true = generate_H_abs(dataset, user)\n",
    "    # plot_environment(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the Environment Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'I2_28B'\n",
    "n_bs_y, n_bs_x = 32, 1\n",
    "n_ue_y, n_ue_x = 32, 1\n",
    "n_paths = 5\n",
    "n_subcarriers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Parameters Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 200\n",
    "n_samples_per_user = 10\n",
    "n_datapoints = n_users * n_samples_per_user # number of (total) datapoints generated\n",
    "\n",
    "\n",
    "noise = gaussian\n",
    "\n",
    "if noise == pink:\n",
    "    amplitude = 0.0001\n",
    "    std = None\n",
    "elif noise == gaussian:\n",
    "    amplitude = None\n",
    "    std = 3*10**(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate & Save Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 402/402 [00:00<00:00, 86043.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToA of some paths of 199 channels with an average total power of 53.50% exceed the useful OFDM symbol duration and are clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating channels: 100%|██████████| 201/201 [00:00<00:00, 5882.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 1/1 [00:00<00:00, 8144.28it/s]\n",
      "Generating channels: 100%|██████████| 1/1 [00:00<00:00, 1028.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1024)\n",
      "(2000, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "noisy_data = np.ndarray((n_datapoints, n_bs_y * n_ue_y))\n",
    "true_data = np.ndarray((n_datapoints, n_bs_y * n_ue_y))\n",
    "index = 0\n",
    "\n",
    "dataset_ = data_generation(scenario_name,\n",
    "                            n_bs_y, n_bs_x, n_ue_y, n_ue_x,\n",
    "                            n_paths, n_subcarriers, 0)\n",
    "\n",
    "for user in range(1,n_users+1):\n",
    "    \n",
    "    H_true = generate_H_abs(dataset_, user)\n",
    "    \n",
    "    H_true = H_true.flatten().reshape(-1,1)\n",
    "    if user == 3:\n",
    "        H_true = H_true.reshape(1,-1)\n",
    "        snr_, snr_db_ = calculate_snr(H_true,H_true + gaussian(H_true, std))\n",
    "    H_true = scaler.fit_transform(H_true)\n",
    "    H_true = H_true.reshape(1,-1)\n",
    "\n",
    "    for i in range(n_samples_per_user):\n",
    "        if noise == pink:\n",
    "            H_added_noise = pink(H_true, amplitude)\n",
    "        elif noise == gaussian:\n",
    "            H_added_noise = gaussian(H_true, std)\n",
    "        H_noise = H_true + H_added_noise\n",
    "        H_noise = H_noise.flatten().reshape(-1,1)\n",
    "        H_noise = scaler.fit_transform(H_noise)\n",
    "        H_noise = H_noise.reshape(1,-1)\n",
    "        noisy_data[index,:] = H_noise\n",
    "        true_data[index,:] = H_true\n",
    "        index += 1\n",
    "\n",
    "\n",
    "print(noisy_data.shape)\n",
    "print(true_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create the datasets in dataframe format\n",
    "true_data_df = pd.DataFrame(true_data)\n",
    "\n",
    "noisy_data_df = pd.DataFrame(noisy_data)\n",
    "\n",
    "\n",
    "# Step 1: Split 80% for training/validation and 20% for testing\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    noisy_data_df,  \n",
    "    true_data_df,\n",
    "    test_size=0.2,   # 20% for testing\n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "# Step 2: Split the remaining 80% into 70% training and 10% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, \n",
    "    y_temp,\n",
    "    test_size=0.125,  # 10% of the original total = 0.1 / 0.8 = 0.125\n",
    "    random_state=42  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "if save:\n",
    "    folder_name = \"../datasets/first_deepmimo_data\"\n",
    "\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    y_train.to_csv(f'{folder_name}/y_data_train.csv', index=False)\n",
    "    y_val.to_csv(f'{folder_name}/y_data_val.csv', index=False)\n",
    "    y_test.to_csv(f'{folder_name}/y_data_test.csv', index=False)\n",
    "    X_train.to_csv(f'{folder_name}/X_data_train.csv', index=False)\n",
    "    X_val.to_csv(f'{folder_name}/X_data_val.csv', index=False)\n",
    "    X_test.to_csv(f'{folder_name}/X_data_test.csv', index=False)\n",
    "\n",
    "    with open(f'{folder_name}/meta_data.txt', \"w\") as file:\n",
    "        # Write text to the file\n",
    "        file.write(f\"SNR = {snr_}\\n\")\n",
    "        file.write(f\"SNR_db = {snr_db_}\\n\")\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
